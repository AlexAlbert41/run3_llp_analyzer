{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a549e7",
   "metadata": {},
   "source": [
    "## Data/MC Comparison for Brem-Induced Clusters\n",
    "\n",
    "#### Comparison of Clusters in Data vs MC. This is to validate the signal reconstruction process. We compare cluster from Z->MuMu events in Data vs those from a DY->ZMuMu (50-120 GeV for MLL). Data is from 2023B&C, and MC is from the preBPix, normalized to the appropriate value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea6d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TInterpreter::ReadRootmapFile>: class  HepMC::FourVector found in libSimDataFormatsGeneratorProducts.so  is already in libHepMC3rootIO.so \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_103/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "import mplhep as hep\n",
    "import pickle\n",
    "import glob\n",
    "import ROOT as rt\n",
    "import coffea\n",
    "import awkward as ak\n",
    "from coffea import hist, processor\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.nanoevents.methods import vector\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e77ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import helper modules for muon scale factor computation\n",
    "sys.path.append(\"/uscms/home/amalbert/nobackup/CMSSW_14_1_0_pre4/src/RazorCommon/Tools/bin\")\n",
    "import importlib\n",
    "import getMuonScaleFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873b2b3",
   "metadata": {},
   "source": [
    "#### Load ntuples as awkward arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd254d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.behavior.update(candidate.behavior)\n",
    "\n",
    "def getLZDF(f,nEvents=-1,version=\"new\"): #lazy dataframe with events that have cluster matched to probe muon\n",
    "    events_raw = uproot.open(f)['MuonSystem']\n",
    "    df = coffea.processor.LazyDataFrame(events_raw,entrystop=nEvents)\n",
    "    start,stop = df._branchargs['entry_start'],df._branchargs['entry_stop']\n",
    "    events = uproot.lazy(df._tree)\n",
    "    #events = events[start:stop]\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a02b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "MC_path = \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/MC_noiseFilters/MC_Summer23/DYto2Mu_MLL-50to120_Merged/DYto2Mu_MLL-50to120_18666pb_weighted.root\"\n",
    "\n",
    "data_path_list = [\"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon0_Run2023B_PromptReco-v1_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon1_Run2023B_PromptReco-v1_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon0_Run2023C_PromptReco-v1_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon1_Run2023C_PromptReco-v1_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon0_Run2023C_PromptReco-v2_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon1_Run2023C_PromptReco-v2_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon0_Run2023C_PromptReco-v3_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon1_Run2023C_PromptReco-v3_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon0_Run2023C_PromptReco-v4_goodLumi.root\",\n",
    "                 \"/store/group/lpclonglived/amalbert/Data_MC_Comp_TnP/results_from_cache_noSkim/Data_noiseFilters/2023_Merged/Muon1_Run2023C_PromptReco-v4_goodLumi.root\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c3d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_MC_full = getLZDF(\"root://cmseos.fnal.gov/\"+MC_path)\n",
    "events_MC_full = events_MC_full[events_MC_full.nCscRechitClusters>0]\n",
    "events_MC_full = events_MC_full[events_MC_full.Flag_all]\n",
    "events_MC_full = events_MC_full[events_MC_full.Flag_ecalBadCalibFilter]\n",
    "events_MC_full = events_MC_full[events_MC_full.jetVeto]\n",
    "\n",
    "data_events = [getLZDF(\"root://cmseos.fnal.gov/\"+data_path) for data_path in data_path_list]\n",
    "events_data_full = ak.concatenate(data_events, axis=0)\n",
    "events_data_full = events_data_full[events_data_full.nCscRechitClusters>0]\n",
    "events_data_full = events_data_full[np.logical_and(events_data_full.ZMass>50, events_data_full.ZMass<120)]\n",
    "events_data_full = events_data_full[events_data_full.Flag_all]\n",
    "events_data_full = events_data_full[events_data_full.Flag_ecalBadCalibFilter]\n",
    "events_data_full = events_data_full[events_data_full.jetVeto]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1940b07",
   "metadata": {},
   "source": [
    "### modify the input ntuples so that each entry corresponds with a cluster. As a result, some entries will be repeated twice (tne ones denoted \"branch names\") if there are two clusters in the event. At this step, all of the branches that we compute for the measurement should be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316d033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cluster level csc branches needed\n",
    "csc_branches = []\n",
    "for branch_name in events_MC_full.fields: \n",
    "    if \"csc\" in branch_name and \"dt\" not in branch_name and \"LLP\" not in branch_name and \"DNN\" not in branch_name:\n",
    "        csc_branches.append(branch_name)\n",
    "\n",
    "#event-level branches        \n",
    "branch_names = [\"runNum\", \"evtNum\", \"weight\", \"pileupWeight\", \"ZMass\", \"met\", \"metPhi\", \"puppiMet\", \"puppiMetPhi\"]\n",
    "\n",
    "#factor to have same number of events in Z-peak (no clusters)\n",
    "kFactor=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ba9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make more useful input awkward array, with all information in cluster-level format\n",
    "def getClusterBranches(LZDF, isMC=False):\n",
    "    new_df = ak.zip({field: ak.flatten(LZDF[field]) for field in csc_branches})\n",
    "    \n",
    "    print(\"finished csc branches\")\n",
    "    newDNN = ak.flatten(ak.mask(LZDF[\"cscRechitClusterDNN_bkgMC_plusBeamHalo\"], LZDF[\"cscRechitClusterDNN_bkgMC_plusBeamHalo\"]>0))\n",
    "    newDNN = newDNN[~ak.is_none(newDNN)]\n",
    "    new_df = ak.with_field(new_df, newDNN, \"cscRechitClusterDNN_bkgMC_plusBeamHalo\")\n",
    "    \n",
    "    for branch in branch_names:\n",
    "        if (not isMC) and (branch in [\"weight\", \"pileupWeight\"]):\n",
    "            continue\n",
    "        new_df = ak.with_field(new_df, np.repeat(LZDF[branch],LZDF[\"nCscRechitClusters\"]), branch)\n",
    "\n",
    "    \n",
    "    column_indices_probe = np.array(ak.flatten(ak.values_astype(LZDF[\"cscRechitCluster_matchToMuon2\"], int)))\n",
    "    column_indices_tag = np.array(ak.flatten(ak.values_astype(LZDF[\"cscRechitCluster_matchToMuon1\"], int)))\n",
    "    row_indices = np.arange(np.size(column_indices_probe), dtype=int)\n",
    "    \n",
    "    #compute \n",
    "    if isMC:\n",
    "        MC_SF_LooseID = getMuonScaleFactor.getLooseIDEffArr_preBPix(np.array(LZDF.lepPt), np.array(LZDF.lepEta))\n",
    "        MC_SF_LooseISO = getMuonScaleFactor.getLooseISOEffArr_preBPix(np.array(LZDF.lepPt), np.array(LZDF.lepEta))\n",
    "        MC_SF_TightID = getMuonScaleFactor.getTightIDEffArr_preBPix(np.array(LZDF.lepPt), np.array(LZDF.lepEta))\n",
    "        MC_SF_TightISO = getMuonScaleFactor.getTightISOEffArr_preBPix(np.array(LZDF.lepPt), np.array(LZDF.lepEta))\n",
    "        MC_SF_HLT = getMuonScaleFactor.getHLTEffArr_preBPix(np.array(LZDF.lepPt), np.array(LZDF.lepEta))\n",
    "        \n",
    "        MC_SF_LooseID = np.repeat(MC_SF_LooseID,np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_probe]\n",
    "        MC_SF_LooseISO = np.repeat(np.array(MC_SF_LooseISO),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_probe]\n",
    "        MC_SF_TightID = np.repeat(MC_SF_TightID,np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_tag]\n",
    "        MC_SF_TightISO = np.repeat(MC_SF_TightISO,np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_tag]\n",
    "        MC_SF_HLT = np.repeat(MC_SF_HLT,np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_tag]\n",
    "        \n",
    "        MC_Weight_Total = new_df[\"weight\"]*MC_SF_LooseID*MC_SF_LooseISO*MC_SF_TightID*MC_SF_TightISO*MC_SF_HLT*kFactor\n",
    "        new_df = ak.with_field(new_df, MC_Weight_Total, \"weight_total\")\n",
    "    \n",
    "    print(\"at muon variables\")\n",
    "    \n",
    "    #load pT, eta, and phi for tag and probe muons\n",
    "    probe_pT = np.repeat(np.array(LZDF[\"lepPt\"]),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_probe]\n",
    "    probe_eta = np.repeat(np.array(LZDF[\"lepEta\"]),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_probe]\n",
    "    probe_phi = np.repeat(np.array(LZDF[\"lepPhi\"]),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_probe]\n",
    "    \n",
    "    tag_pT = np.repeat(np.array(LZDF[\"lepPt\"]),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_tag]\n",
    "    tag_eta = np.repeat(np.array(LZDF[\"lepEta\"]),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_tag]\n",
    "    tag_phi = np.repeat(np.array(LZDF[\"lepPhi\"]),np.array(LZDF[\"nCscRechitClusters\"]), axis=0)[row_indices,column_indices_tag]\n",
    "    \n",
    "    new_df = ak.with_field(new_df, probe_pT, \"probe_pT\")\n",
    "    new_df = ak.with_field(new_df, probe_eta, \"probe_eta\")\n",
    "    new_df = ak.with_field(new_df, probe_phi, \"probe_phi\")\n",
    "    \n",
    "    new_df = ak.with_field(new_df, tag_pT, \"tag_pT\")\n",
    "    new_df = ak.with_field(new_df, tag_eta, \"tag_eta\")\n",
    "    new_df = ak.with_field(new_df, tag_phi, \"tag_phi\")\n",
    "    \n",
    "    #deltaR(cluster, muon)\n",
    "    new_df = ak.with_field(new_df, np.sqrt((new_df[\"cscRechitClusterEta\"]-new_df[\"probe_eta\"])**2+(new_df[\"cscRechitClusterPhi\"]-new_df[\"probe_phi\"])**2), \"cscRechitClusterMuonDeltaR\")\n",
    "    \n",
    "    #DNN inputs - hit fractions in stations/rings\n",
    "    new_df = ak.with_field(new_df, (new_df.cscRechitClusterNRechitChamberPlus11+new_df.cscRechitClusterNRechitChamberMinus11+new_df.cscRechitClusterNRechitChamberPlus12+new_df.cscRechitClusterNRechitChamberMinus12+new_df.cscRechitClusterNRechitChamberPlus13+new_df.cscRechitClusterNRechitChamberMinus13)/new_df.cscRechitClusterSize, \"cscRechitClusterFracS1\")\n",
    "    new_df = ak.with_field(new_df, (new_df.cscRechitClusterNRechitChamberPlus21+new_df.cscRechitClusterNRechitChamberMinus21+new_df.cscRechitClusterNRechitChamberPlus22+new_df.cscRechitClusterNRechitChamberMinus22)/new_df.cscRechitClusterSize, \"cscRechitClusterFracS2\")\n",
    "    new_df = ak.with_field(new_df, (new_df.cscRechitClusterNRechitChamberPlus31+new_df.cscRechitClusterNRechitChamberMinus31+new_df.cscRechitClusterNRechitChamberPlus32+new_df.cscRechitClusterNRechitChamberMinus32)/new_df.cscRechitClusterSize, \"cscRechitClusterFracS3\")\n",
    "    new_df = ak.with_field(new_df, (new_df.cscRechitClusterNRechitChamberPlus41+new_df.cscRechitClusterNRechitChamberMinus41+new_df.cscRechitClusterNRechitChamberPlus42+new_df.cscRechitClusterNRechitChamberMinus42)/new_df.cscRechitClusterSize, \"cscRechitClusterFracS4\")\n",
    "\n",
    "    new_df = ak.with_field(new_df,(new_df.cscRechitClusterNRechitChamberPlus11+new_df.cscRechitClusterNRechitChamberMinus11+new_df.cscRechitClusterNRechitChamberPlus21+new_df.cscRechitClusterNRechitChamberMinus21+new_df.cscRechitClusterNRechitChamberPlus31+new_df.cscRechitClusterNRechitChamberMinus31+new_df.cscRechitClusterNRechitChamberPlus41+new_df.cscRechitClusterNRechitChamberMinus41)/new_df.cscRechitClusterSize, \"cscRechitClusterFracR1\")\n",
    "    new_df = ak.with_field(new_df, (new_df.cscRechitClusterNRechitChamberPlus12+new_df.cscRechitClusterNRechitChamberMinus12+new_df.cscRechitClusterNRechitChamberPlus22+new_df.cscRechitClusterNRechitChamberMinus22+new_df.cscRechitClusterNRechitChamberPlus32+new_df.cscRechitClusterNRechitChamberMinus32+new_df.cscRechitClusterNRechitChamberPlus42+new_df.cscRechitClusterNRechitChamberMinus42)/new_df.cscRechitClusterSize, \"cscRechitClusterFracR2\")\n",
    "    new_df = ak.with_field(new_df, (new_df.cscRechitClusterNRechitChamberPlus13+new_df.cscRechitClusterNRechitChamberMinus13)/new_df.cscRechitClusterSize, \"cscRechitClusterFracR3\")\n",
    "    \n",
    "    #forward hits branch\n",
    "    new_df = ak.with_field(new_df, new_df.cscRechitClusterNRechitChamberPlus11+new_df.cscRechitClusterNRechitChamberMinus11+new_df.cscRechitClusterNRechitChamberPlus12 + new_df.cscRechitClusterNRechitChamberMinus12, \"forward_hits\")\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622a4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC\n",
      "finished csc branches\n",
      "at muon variables\n",
      "now data\n",
      "finished csc branches\n",
      "at muon variables\n"
     ]
    }
   ],
   "source": [
    "print(\"MC\")\n",
    "events_MC = getClusterBranches(events_MC_full, True)\n",
    "print(\"now data\")\n",
    "events_data = getClusterBranches(events_data_full, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00150cd9",
   "metadata": {},
   "source": [
    "### Code to Mask Data According to Specific Cuts - Low MET and High MET, along with cutflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0508581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEventMask(events, noMaskList: list=[], noCuts=False):\n",
    "    mask = events.cscRechitCluster_matchToProbeMuon\n",
    "    #mask out hotspot automatically\n",
    "    mask=ak.mask(mask, np.logical_or(np.logical_and(np.logical_or(events.cscRechitClusterPhi<-0.3,events.cscRechitClusterPhi>0.6),abs(events.cscRechitClusterPhi)<2.8), events.cscRechitClusterEta>-1.9))\n",
    "    if \"forward_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.forward_hits==0)\n",
    "    if noCuts:\n",
    "        return mask\n",
    "    if \"timespread_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterTimeSpreadWeightedAll<20)\n",
    "    if \"time_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterTimeWeighted<12.5)\n",
    "        mask = ak.mask(mask, events.cscRechitClusterTimeWeighted>-5)\n",
    "    if \"DNN_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterDNN_bkgMC_plusBeamHalo>0.96)\n",
    "    if \"clusterSize_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterSize>160)\n",
    "    if \"NStation10_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterNStation10>1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4563b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEventMaskHighMET(events, noMaskList: list=[], noCuts=False):\n",
    "    mask = events.cscRechitCluster_matchToProbeMuon\n",
    "    #mask out hotspot automatically\n",
    "    mask=ak.mask(mask, np.logical_or(np.logical_and(np.logical_or(events.cscRechitClusterPhi<-0.3,events.cscRechitClusterPhi>0.6),abs(events.cscRechitClusterPhi)<2.8), events.cscRechitClusterEta>-1.9))\n",
    "    if \"forward_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, (events.cscRechitClusterNRechitChamberPlus11+events.cscRechitClusterNRechitChamberMinus11)/events.cscRechitClusterSize<1)\n",
    "    if noCuts:\n",
    "        return mask\n",
    "    if \"timespread_veto\" not in noMaskList: #not actually applied in the analysis\n",
    "        mask = ak.mask(mask, events.cscRechitClusterTimeSpreadWeightedAll<20)\n",
    "    if \"time_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterTimeWeighted<12.5)\n",
    "        mask = ak.mask(mask, events.cscRechitClusterTimeWeighted>-5)\n",
    "    if \"DNN_veto\" not in noMaskList: # not actually applied in the analysis\n",
    "        mask = ak.mask(mask, events.cscRechitClusterDNN_bkgMC_plusBeamHalo>0.96)\n",
    "    if \"clusterSize_veto\" not in noMaskList:\n",
    "        mask = ak.mask(mask, events.cscRechitClusterSize>150) #150 instead of 160 for low MET\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3830d516",
   "metadata": {},
   "source": [
    "#### compute efficiencies (no cuts applied other than forward veto or high MET equivalent, except for measurement of forward veto efficiency itself)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872e605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing low MET efficiencies in Data\n",
      "Data Denominator no forward veto:  1979690\n",
      "Data Denominator:  35941\n",
      "Forward Veto Efficiency:  1.8154862630007726\n",
      "Timespread Veto Efficiency:  77.84980940986617\n",
      "Time Veto Efficiency:  97.96332878884839\n",
      "DNN Veto Efficiency:  17.581592053643472\n",
      "ClusterSize Veto Efficiency:  4.671545032136001\n",
      "ClusterSize Veto Efficiency:  32.86775548816115\n"
     ]
    }
   ],
   "source": [
    "# data efficiencies\n",
    "print(\"computing low MET efficiencies in Data\")\n",
    "\n",
    "denom_noForward = ak.count_nonzero(makeEventMask(events_data, [\"forward_veto\"], True))\n",
    "print(\"Data Denominator no forward veto: \", denom_noForward)\n",
    "\n",
    "\n",
    "denom = ak.count_nonzero(makeEventMask(events_data, [], True))\n",
    "print(\"Data Denominator: \", denom)\n",
    "\n",
    "num_forward = ak.count_nonzero(makeEventMask(events_data, [], True))\n",
    "print(\"Forward Veto Efficiency: \", num_forward/denom_noForward*100)\n",
    "\n",
    "num_timespread = ak.count_nonzero(makeEventMask(events_data, ['clusterSize_veto','DNN_veto','time_veto', \"NStation10_veto\"]))\n",
    "print(\"Timespread Veto Efficiency: \", num_timespread/denom*100)\n",
    "\n",
    "num_time = ak.count_nonzero(makeEventMask(events_data, ['clusterSize_veto','DNN_veto','timespread_veto', \"NStation10_veto\"]))\n",
    "print(\"Time Veto Efficiency: \", num_time/denom*100)\n",
    "\n",
    "num_DNN = ak.count_nonzero(makeEventMask(events_data, ['timespread_veto','clusterSize_veto','time_veto', \"NStation10_veto\"]))\n",
    "print(\"DNN Veto Efficiency: \", num_DNN/denom*100)\n",
    "\n",
    "num_clusterSize = ak.count_nonzero(makeEventMask(events_data, ['timespread_veto','DNN_veto','time_veto', \"NStation10_veto\"]))\n",
    "print(\"ClusterSize Veto Efficiency: \", num_clusterSize/denom*100)\n",
    "\n",
    "num_NStation10 = ak.count_nonzero(makeEventMask(events_data, ['timespread_veto','DNN_veto','time_veto', 'clusterSize_veto']))\n",
    "print(\"ClusterSize Veto Efficiency: \", num_NStation10/denom*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1299e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing low MET efficiencies in MC\n",
      "MC Denominator:  1526925.2573239096\n",
      "MC Denominator:  45511.05365695244\n",
      "Forward Veto Efficiency:  0.5721386483183599\n",
      "Timespread Veto Efficiency:  96.61940932280766\n",
      "Time Veto Efficiency:  99.06142000586422\n",
      "DNN Veto Efficiency:  19.225600787151546\n",
      "ClusterSize Veto Efficiency:  7.20583866430492\n",
      "ClusterSize Veto Efficiency:  2.8872106761238836\n"
     ]
    }
   ],
   "source": [
    "print(\"computing low MET efficiencies in MC\")\n",
    "\n",
    "\n",
    "denom = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC, ['forward_veto'], True)))\n",
    "print(\"MC Denominator: \", denom)\n",
    "\n",
    "\n",
    "denom = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC, [], True)))\n",
    "print(\"MC Denominator: \", denom)\n",
    "\n",
    "num_forward = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC,[])))\n",
    "print(\"Forward Veto Efficiency: \", num_forward/denom*100)\n",
    "\n",
    "num_timespread = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC,['clusterSize_veto','DNN_veto','time_veto', \"NStation10_veto\"])))\n",
    "print(\"Timespread Veto Efficiency: \", num_timespread/denom*100)\n",
    "\n",
    "num_time = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC,['timespread_veto','clusterSize_veto','DNN_veto', \"NStation10_veto\"])))\n",
    "print(\"Time Veto Efficiency: \", num_time/denom*100)\n",
    "\n",
    "num_DNN = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC,['timespread_veto','clusterSize_veto','time_veto', \"NStation10_veto\"])))\n",
    "print(\"DNN Veto Efficiency: \", num_DNN/denom*100)\n",
    "\n",
    "num_clusterSize = ak.sum(ak.mask(events_MC.weight_total, makeEventMask(events_MC, ['timespread_veto','DNN_veto','time_veto', \"NStation10_veto\"])))\n",
    "print(\"ClusterSize Veto Efficiency: \", num_clusterSize/denom*100)\n",
    "\n",
    "num_NStation10 = ak.count_nonzero(makeEventMask(events_MC, ['timespread_veto','DNN_veto','time_veto', 'clusterSize_veto']))\n",
    "print(\"ClusterSize Veto Efficiency: \", num_NStation10/denom*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0daf3b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing high MET efficiencies in Data\n",
      "Data Denominator no forward veto:  1979690\n",
      "Data Denominator:  1979689\n",
      "Forward Veto Efficiency:  99.9999494870409\n",
      "Timespread Veto Efficiency:  43.933971447030316\n",
      "Time Veto Efficiency:  92.70900631361795\n",
      "DNN Veto Efficiency:  25.50956236055259\n",
      "ClusterSize Veto Efficiency:  5.0382661114952905\n"
     ]
    }
   ],
   "source": [
    "# data efficiencies\n",
    "print(\"computing high MET efficiencies in Data\")\n",
    "\n",
    "denom_noForward = ak.count_nonzero(makeEventMaskHighMET(events_data, [\"forward_veto\"], True))\n",
    "print(\"Data Denominator no forward veto: \", denom_noForward)\n",
    "\n",
    "\n",
    "denom = ak.count_nonzero(makeEventMaskHighMET(events_data, [], True))\n",
    "print(\"Data Denominator: \", denom)\n",
    "\n",
    "num_forward = ak.count_nonzero(makeEventMaskHighMET(events_data, [], True))\n",
    "print(\"Forward Veto Efficiency: \", num_forward/denom_noForward*100)\n",
    "\n",
    "num_timespread = ak.count_nonzero(makeEventMaskHighMET(events_data, ['clusterSize_veto','DNN_veto','time_veto']))\n",
    "print(\"Timespread Veto Efficiency: \", num_timespread/denom*100)\n",
    "\n",
    "num_time = ak.count_nonzero(makeEventMaskHighMET(events_data, ['clusterSize_veto','DNN_veto','timespread_veto']))\n",
    "print(\"Time Veto Efficiency: \", num_time/denom*100)\n",
    "\n",
    "num_DNN = ak.count_nonzero(makeEventMaskHighMET(events_data, ['timespread_veto','clusterSize_veto','time_veto']))\n",
    "print(\"DNN Veto Efficiency: \", num_DNN/denom*100)\n",
    "\n",
    "\n",
    "num_clusterSize = ak.count_nonzero(makeEventMaskHighMET(events_data, ['timespread_veto','DNN_veto','time_veto']))\n",
    "print(\"ClusterSize Veto Efficiency: \", num_clusterSize/denom*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5453897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing high MET efficiencies in MC\n",
      "MC Denominator:  1526925.2573239096\n",
      "MC Denominator:  1526925.2573239096\n",
      "Forward Veto Efficiency:  2.179963802504804\n",
      "Timespread Veto Efficiency:  74.11686459542427\n",
      "Time Veto Efficiency:  92.28292796597655\n",
      "DNN Veto Efficiency:  27.27347076668621\n",
      "ClusterSize Veto Efficiency:  6.00871973194476\n"
     ]
    }
   ],
   "source": [
    "print(\"computing high MET efficiencies in MC\")\n",
    "\n",
    "\n",
    "denom = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC, ['forward_veto'], True)))\n",
    "print(\"MC Denominator: \", denom)\n",
    "\n",
    "\n",
    "denom = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC, [], True)))\n",
    "print(\"MC Denominator: \", denom)\n",
    "\n",
    "num_forward = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC,[])))\n",
    "print(\"Forward Veto Efficiency: \", num_forward/denom*100)\n",
    "\n",
    "num_timespread = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC,['clusterSize_veto','DNN_veto','time_veto'])))\n",
    "print(\"Timespread Veto Efficiency: \", num_timespread/denom*100)\n",
    "\n",
    "num_time = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC,['timespread_veto','clusterSize_veto','DNN_veto'])))\n",
    "print(\"Time Veto Efficiency: \", num_time/denom*100)\n",
    "\n",
    "num_DNN = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC,['timespread_veto','clusterSize_veto','time_veto'])))\n",
    "print(\"DNN Veto Efficiency: \", num_DNN/denom*100)\n",
    "\n",
    "num_clusterSize = ak.sum(ak.mask(events_MC.weight_total, makeEventMaskHighMET(events_MC, ['timespread_veto','DNN_veto','time_veto'])))\n",
    "print(\"ClusterSize Veto Efficiency: \", num_clusterSize/denom*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b4759",
   "metadata": {},
   "source": [
    "### Helper functions to make histograms and style them appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccc405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.gStyle.SetOptStat(0)\n",
    "def make_ratio_plot(h_list_in, title = \"\", label = \"\", fit = False, in_tags = None, ratio_bounds = [0.1, 4], logy = False, ratio_index = 0, draw_opt = ['E2','E1'], text = \"\", scale=False, scales = [1,1]):\n",
    "    h_list = []\n",
    "    if in_tags == None:\n",
    "        tag = []\n",
    "    else:\n",
    "        tag = in_tags\n",
    "    for i, h in enumerate(h_list_in):\n",
    "        h_list.append(h.Clone('h{}aux{}'.format(i, label)))\n",
    "        if in_tags == None:\n",
    "            tag.append(h.GetTitle())\n",
    "    #print(\"tags: \", tag)\n",
    "    c_out = rt.TCanvas(\"c_out_ratio\"+label, \"c_out_ratio\"+label, 800, 800)\n",
    "    pad1 = rt.TPad(\"pad1\", \"pad1\", 0, 0.3, 1, 1.0)\n",
    "    pad1.SetBottomMargin(0.03)\n",
    "    pad1.SetLeftMargin(0.15)\n",
    "    pad1.SetRightMargin(0.04)# pad2.SetGrid()\n",
    "    if logy:\n",
    "        pad1.SetLogy()\n",
    "\n",
    "    pad1.Draw()\n",
    "    pad1.cd()\n",
    "\n",
    "    leg = rt.TLegend(0.5, 0.65, 0.9, 0.92)\n",
    "    leg = rt.TLegend(0.7, 0.65, 0.9, 0.92)\n",
    "\n",
    "    #leg = rt.TLegend(0.2, 0.7, 0.5, 0.9)\n",
    "    # leg = rt.TLegend(0.7, 0.2, 0.9, 0.4)\n",
    "    leg.SetBorderSize(0)\n",
    "    leg.SetTextSize(0.045)\n",
    "    leg.SetFillStyle(0)\n",
    "    c_out.cd(1)\n",
    "\n",
    "    scaled_h_list = []\n",
    "    if scale:\n",
    "        for i, h_unscaled in enumerate(h_list):\n",
    "            #h = h_unscaled.Clone()\n",
    "            #h = h_unscaled.Scale(1/scales[i])\n",
    "            #scaled_h_list.append(h_unscaled.Clone())\n",
    "            h_unscaled.Scale(1/scales[i])\n",
    "            scaled_h_list.append(h_unscaled)\n",
    "    else:\n",
    "        #for i, h_unscaled in enumerate(h_list):\n",
    "            #h = h_unscaled.Clone()\n",
    "            #scaled_h_list.append(h)\n",
    "        scaled_h_list = h_list\n",
    "    for i, h in enumerate(scaled_h_list):\n",
    "        h.GetXaxis().SetLabelSize(0)\n",
    "        h.GetXaxis().SetTitle(label)\n",
    "        h.GetYaxis().SetRangeUser(0, 1.1*max(map(lambda x: x.GetMaximum(), scaled_h_list)))\n",
    "        if logy and not scale:\n",
    "            h.GetYaxis().SetRangeUser(10e-2, 2*max(map(lambda x: x.GetMaximum(), scaled_h_list)))\n",
    "        if logy and scale:\n",
    "            h.GetYaxis().SetRangeUser(10e-4, 1)\n",
    "        h.GetYaxis().SetTitleOffset(1.0)\n",
    "        h.GetYaxis().SetTitleSize(0.06)\n",
    "        h.GetYaxis().SetLabelSize(0.05)\n",
    "        \n",
    "        if scale:\n",
    "            y_title = \"Fraction of Events\"\n",
    "        else:\n",
    "            y_title = \"Events\"\n",
    "        \n",
    "        h.GetYaxis().SetTitle()\n",
    "        h.SetTitle(f\"{title};adsf;{y_title}\")\n",
    "        #if ratio_index == 0:h.DrawCopy(\"hist\")\n",
    "        '''\n",
    "        h.SetFillColor(h_list_in[i].GetLineColor())\n",
    "        h.SetFillStyle(3002)\n",
    "        #h.SetStats(1)\n",
    "        h.SetLineColor(h_list_in[i].GetLineColor())\n",
    "        h.SetLineWidth(2)\n",
    "        h.SetMarkerColor(h_list_in[i].GetLineColor())\n",
    "        h.SetMarkerSize(2)\n",
    "        # if ratio_index == 0:\n",
    "        #     # h.DrawCopy(\"hist\")\n",
    "        #     h.DrawCopy(draw_opt[i]+'same')\n",
    "        # else:h.DrawCopy(draw_opt[i])\n",
    "        #if ratio_index == 0 :h.DrawCopy(draw_opt[i]+\"same\")\n",
    "        #h.DrawCopy(\"E2 HIST\")\n",
    "        '''\n",
    "        if i==0:\n",
    "            h.SetLineWidth(4)\n",
    "            h.DrawCopy(\"hist\")\n",
    "            #h.SetFillStyle(0)\n",
    "            h.SetFillColor(h_list_in[i].GetLineColor())\n",
    "            h.SetFillStyle(3002)\n",
    "            #h.SetStats(1)\n",
    "            h.SetLineColor(h_list_in[i].GetLineColor())\n",
    "            h.SetLineWidth(2)\n",
    "            h.SetMarkerColor(h_list_in[i].GetLineColor())\n",
    "            h.SetMarkerSize(2)\n",
    "            h.DrawCopy(draw_opt[i] + \"same\")\n",
    "            #h.SetFillStyle(0)\n",
    "        else:\n",
    "            h.SetLineWidth(2)\n",
    "            h.DrawCopy(draw_opt[i] + \"same\")\n",
    "        #else:h.DrawCopy(draw_opt[i])\n",
    "        if len(text)>0:\n",
    "            l = rt.TLatex()\n",
    "            l.SetTextSize(0.045)\n",
    "            if logy:l.DrawLatex((h.GetXaxis().GetXmax()-h.GetXaxis().GetXmin())*0.1+h.GetXaxis().GetXmin() , h.GetMaximum()/10, text)\n",
    "            else:l.DrawLatex((h.GetXaxis().GetXmax()-h.GetXaxis().GetXmin())*0.1+h.GetXaxis().GetXmin() , h.GetMaximum()*0.8, text)\n",
    "        #if i==1:\n",
    "            #h.DrawCopy(draw_opt[i]+\"same\")\n",
    "       #     h.Draw(\"E1 same\")\n",
    "\n",
    "        leg.AddEntry(h, tag[i], \"lep\")\n",
    "    leg.Draw(\"same\")\n",
    "    cmsText = rt.TLatex()\n",
    "\n",
    "    cmsText.SetNDC(True)\n",
    "\n",
    "    cmsText.SetTextFont(42);  \n",
    "    cmsText.SetTextSize(0.045);\n",
    "    cmsText.SetTextAlign(11); \n",
    "    cmsText.DrawLatex(0.17, 0.85, \"#bf{CMS Work in progress}\") \n",
    "\n",
    "    c_out.cd()\n",
    "    pad2 = rt.TPad(\"pad2\", \"pad2\", 0, 0, 1, 0.3)\n",
    "    pad2.SetTopMargin(0.03)\n",
    "    pad2.SetBottomMargin(0.25)\n",
    "    pad2.SetLeftMargin(0.15)\n",
    "    pad2.SetRightMargin(0.04)# pad2.SetGrid()\n",
    "    pad2.Draw()\n",
    "    pad2.cd()\n",
    "    band = scaled_h_list[ratio_index].Clone('h_band')\n",
    "    for j in range(band.GetXaxis().GetNbins()):\n",
    "        band.SetBinContent(j+1, 1.0)\n",
    "        if h_list[ratio_index].GetBinContent(j+1) == 0:\n",
    "            band.SetBinError(j+1, 0.0)\n",
    "        else:\n",
    "            band.SetBinError(j+1, scaled_h_list[ratio_index].GetBinError(j+1)/scaled_h_list[ratio_index].GetBinContent(j+1))\n",
    "            #print(j, h_list_in[0].GetBinError(j+1)/h_list_in[0].GetBinContent(j+1))\n",
    "    band.SetFillColor(scaled_h_list[ratio_index].GetLineColor())\n",
    "\n",
    "    band.SetFillStyle(3002)\n",
    "    band.SetLineColor(scaled_h_list[ratio_index].GetLineColor())\n",
    "    #band.SetFillColorAlpha(0,0)\n",
    "    #band.SetLineColor(0)\n",
    "    \n",
    "    band.GetYaxis().SetTitleOffset(0.5)\n",
    "    band.GetYaxis().SetRangeUser(ratio_bounds[0], ratio_bounds[1])\n",
    "    band.GetYaxis().SetTitleSize(0.11)\n",
    "    band.GetYaxis().SetLabelSize(0.12)\n",
    "    band.GetYaxis().SetNdivisions(506)\n",
    "    band.GetXaxis().SetTitleOffset(0.95)\n",
    "    band.GetXaxis().SetTitleSize(0.12)\n",
    "    band.GetXaxis().SetLabelSize(0.12)\n",
    "    band.GetXaxis().SetTickSize(0.07)\n",
    "    \n",
    "    band.SetYTitle('Ratio with {}'.format(tag[ratio_index]))\n",
    "    band.SetXTitle(label)\n",
    "    band.SetTitle(\"\")\n",
    "    band.DrawCopy('E2')\n",
    "    ln = rt.TLine(h.GetXaxis().GetXmin(), 1, h.GetXaxis().GetXmax(), 1)\n",
    "    ln.SetLineWidth(3)\n",
    "    ln.SetLineColor(scaled_h_list[ratio_index].GetLineColor())\n",
    "    ln.DrawLine(h.GetXaxis().GetXmin(), 1, h.GetXaxis().GetXmax(), 1)\n",
    "     \n",
    "    #print(ratio_index)\n",
    "    for i, h in enumerate(scaled_h_list):\n",
    "        if i == ratio_index:\n",
    "            continue\n",
    "        else:\n",
    "            if fit:h.GetFunction(\"expo\")\n",
    "            h.Divide(scaled_h_list[ratio_index])\n",
    "            # h.GetYaxis().SetTitleOffset(0.6)\n",
    "            # h.GetYaxis().SetRangeUser(ratio_bounds[0], ratio_bounds[1])\n",
    "            # h.GetYaxis().SetTitleSize(0.12)\n",
    "            # h.GetYaxis().SetLabelSize(0.12)\n",
    "            # h.GetYaxis().SetNdivisions(506)\n",
    "            # h.GetXaxis().SetTitleOffset(0.95)\n",
    "            # h.GetXaxis().SetTitleSize(0.12)\n",
    "            # h.GetXaxis().SetLabelSize(0.12)\n",
    "            # h.GetXaxis().SetTickSize(0.07)\n",
    "            # h.SetYTitle('Ratio with {}'.format(tag[0]))\n",
    "            # h.SetTitle(\"\")\n",
    "            #set relative error of ratio to be the relative error of data\n",
    "            for j in range(h.GetXaxis().GetNbins()):\n",
    "                if h_list[i].GetBinContent(j+1) == 0:\n",
    "                    h.SetBinError(j+1, 0.0)\n",
    "                else:\n",
    "                    h.SetBinError(j+1, h_list_in[i].GetBinError(j+1)/h_list_in[i].GetBinContent(j+1)*h.GetBinContent(j+1))\n",
    "            h.Draw('same'+draw_opt[i])\n",
    "    \n",
    "    pad2.Update()\n",
    "    \n",
    "    c_out.pad1 = pad1\n",
    "    c_out.pad2 = pad2\n",
    "    c_out.h_list = h_list\n",
    "    c_out.leg = leg\n",
    "    \n",
    "    \n",
    "    return c_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a22776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to build histograms\n",
    "\n",
    "def makeHists(events_data, events_MC, branch, mask_array, bins_tuple, highMET = False):\n",
    "    print(f\"on branch {branch}\")\n",
    "    \n",
    "    nbins, lowBin, highBin = bins_tuple\n",
    "    \n",
    "    #loop over three types of plots (no cuts, just forward veto, all cuts other than that measured)\n",
    "    name_strs = [\"noCuts\", \"forwardVeto\", \"allOtherCuts\"]\n",
    "    masks = [[\"forward_veto\"], [], mask_array]\n",
    "    mask_bools = [True, True, False]\n",
    "    \n",
    "    hist_info = {}\n",
    "    for plotType, mask_list, mask_bool in zip(name_strs, masks, mask_bools):\n",
    "    \n",
    "        #compute relevant mask for particular plot\n",
    "        if not highMET:\n",
    "            mask_data = makeEventMask(events_data, mask_list, mask_bool)\n",
    "            mask_MC = makeEventMask(events_MC, mask_list, mask_bool)\n",
    "        else:\n",
    "            mask_data = makeEventMaskHighMET(events_data, mask_list, mask_bool)\n",
    "            mask_MC = makeEventMaskHighMET(events_MC, mask_list, mask_bool)\n",
    "    \n",
    "        data_tree = events_data[mask_data]\n",
    "        data_tree = data_tree[~ak.is_none(data_tree)]\n",
    "        \n",
    "        MC_tree = events_MC[mask_MC]\n",
    "        MC_tree = MC_tree[~ak.is_none(MC_tree)]\n",
    "    \n",
    "        #initialize data and MC histograms\n",
    "        data = rt.TH1F(\"Data\", \"Data\", nbinsx=nbins, xlow = lowBin, xup=highBin)\n",
    "        MC = rt.TH1F(\"MC\", \"MC\", nbinsx=nbins, xlow = lowBin, xup=highBin)\n",
    "\n",
    "\n",
    "        #build data hist\n",
    "        data_arr = np.array(data_tree[branch], dtype=np.float64)\n",
    "        data_size = np.size(data_arr)\n",
    "        data_weights = np.ones(data_size, dtype=np.float64)\n",
    "        data.FillN(data_size, data_arr, data_weights)\n",
    "        data.SetLineColor(rt.kBlack)\n",
    "        data.SetFillStyle(0)\n",
    "        \n",
    "        #build MC hist\n",
    "        MC_arr = np.array(MC_tree[branch], dtype=np.float64)\n",
    "        MC_size = np.size(MC_arr)\n",
    "        MC_weights = np.array(MC_tree[\"weight_total\"])\n",
    "        MC.FillN(MC_size, MC_arr, MC_weights)\n",
    "        MC.SetLineColor(rt.kRed)\n",
    "        MC.SetFillStyle(0)\n",
    "        \n",
    "        sumOfWeights = ak.sum(MC_tree[\"weight_total\"])\n",
    "        \n",
    "        hist_info[branch+\"_\"+plotType] = {\"MC_hist\": MC, \"data_hist\": data, \n",
    "                                          \"MC_weights\": sumOfWeights, \"data_weights\": data_size}\n",
    "        \n",
    "    return hist_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910482e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dictionary with relevant plot info\n",
    "plot_info = {\"ZMass\": {\"filename_base\":\"ZMass\", \"title\":\"Dimuon Mass Distribution\", \n",
    "                       \"xlabel\":\"Dimuon Mass [GeV]\", \"masks\":[],\"bins\":(80, 0, 150), \"logy\":False},\n",
    "             \"puppiMet\": {\"filename_base\":\"puppiMet\", \"title\":\"PUPPI MET Distribution\", \n",
    "                       \"xlabel\":\"PUPPI MET [GeV]\", \"masks\":[],\"bins\":(60, -5, 100), \"logy\":False},\n",
    "            \"puppiMetPhi\": {\"filename_base\":\"puppiMetPhi\", \"title\":\"PUPPI MET Phi Distribution\", \n",
    "                       \"xlabel\":\"PUPPI MET Phi\", \"masks\":[],\"bins\":(30, -4, 4), \"logy\":False},\n",
    "            \"cscRechitClusterMuonDeltaR\": {\"filename_base\":\"cluster_muon_deltaR\", \"title\":\"deltaR(cluster, muon)\", \n",
    "                       \"xlabel\":\"deltaR(cluster, muon)\", \"masks\":[],\"bins\":(50, 0, 0.5), \"logy\":False},\n",
    "            \"probe_pT\": {\"filename_base\":\"probe_pT\", \"title\":\"pT of Muon Matched to Cluster\", \n",
    "                       \"xlabel\":\"pT [GeV]\", \"masks\":[],\"bins\":(25, 0, 100), \"logy\":False},\n",
    "            \"tag_pT\": {\"filename_base\":\"tag_pT\", \"title\":\"pT of Muon Not Matched to Cluster\", \n",
    "                       \"xlabel\":\"pT [GeV]\", \"masks\":[],\"bins\":(25, 0, 100), \"logy\":False},\n",
    "            \"probe_phi\": {\"filename_base\":\"probe_phi\", \"title\":\"Phi of Muon Matched to Cluster\", \n",
    "                       \"xlabel\":\"pT [GeV]\", \"masks\":[],\"bins\":(60, -4, 4), \"logy\":False},\n",
    "            \"tag_phi\": {\"filename_base\":\"tag_phi\", \"title\":\"Phi of Muon Not Matched to Cluster\", \n",
    "                       \"xlabel\":\"pT [GeV]\", \"masks\":[],\"bins\":(60, -4, 4), \"logy\":False},\n",
    "            \"probe_eta\": {\"filename_base\":\"probe_eta\", \"title\":\"Eta of Muon Matched to Cluster\", \n",
    "                       \"xlabel\":\"pT [GeV]\", \"masks\":[],\"bins\":(60, -4, 4), \"logy\":False},\n",
    "            \"tag_eta\": {\"filename_base\":\"tag_eta\", \"title\":\"Eta of Muon Not Matched to Cluster\", \n",
    "                       \"xlabel\":\"pT [GeV]\", \"masks\":[],\"bins\":(60, -4, 4), \"logy\":False},\n",
    "            \"cscRechitClusterSize\": {\"filename_base\":\"cscRechitClusterSize\", \"title\":\"Cluster Size Distribution\", \n",
    "                       \"xlabel\":\"N_{hits}\", \"masks\":[\"clusterSize_veto\"],\"bins\":(40, 0, 400), \"logy\":True},\n",
    "            \"cscRechitClusterDNN_bkgMC_plusBeamHalo\": {\"filename_base\":\"DNN_Score\", \"title\":\"DNN Score Distribution\", \n",
    "                       \"xlabel\":\"DNN Score\", \"masks\":[\"DNN_veto\"],\"bins\":(12, 0.52, 1), \"logy\":True},\n",
    "            \"cscRechitClusterTimeWeighted\": {\"filename_base\":\"Cluster_Time\", \"title\":\"Weighted Cluster Time Distribution\", \n",
    "                       \"xlabel\":\"Weighted Cluster Time [ns]\", \"masks\":[\"time_veto\"],\"bins\":(60, -8, 20), \"logy\":False},\n",
    "            \"cscRechitClusterTimeSpreadWeightedAll\": {\"filename_base\":\"Cluster_Timespread\", \"title\":\"Weighted Cluster Timespread Distribution\", \n",
    "                       \"xlabel\":\"Weighted Cluster Timespread [ns]\", \"masks\":[\"timespread_veto\"],\"bins\":(60, 0, 50), \"logy\":False},\n",
    "            \"cscRechitClusterEta\": {\"filename_base\":\"cluster_eta\", \"title\":\"Cluster Eta\", \n",
    "                       \"xlabel\":\"Eta\", \"masks\":[],\"bins\":(60, -4, 4), \"logy\":False},\n",
    "            \"cscRechitClusterPhi\": {\"filename_base\":\"cluster_phi\", \"title\":\"Cluster Phi\", \n",
    "                       \"xlabel\":\"Phi\", \"masks\":[],\"bins\":(60, -4, 4), \"logy\":False},\n",
    "             \"cscRechitClusterNStation10\": {\"filename_base\":\"cluster_NStation10\", \"title\":\"Number of Stations with >=10 Rechits\", \n",
    "                       \"xlabel\":\"# of Stations\", \"masks\":[],\"bins\":(5, 0, 5), \"logy\":False},\n",
    "            \"cscRechitClusterXSpread\": {\"filename_base\":\"cscRechitClusterXSpread\", \"title\":\"Cluster X Spread\", \n",
    "                       \"xlabel\":\"X Spread [cm]\", \"masks\":[],\"bins\":(25, -5, 150), \"logy\": False},\n",
    "            \"cscRechitClusterYSpread\": {\"filename_base\":\"cscRechitClusterYSpread\", \"title\":\"Cluster Y Spread\", \n",
    "                       \"xlabel\":\"Y Spread [cm]\", \"masks\":[],\"bins\":(25, -5, 150), \"logy\": False},\n",
    "            \"cscRechitClusterZSpread\": {\"filename_base\":\"cscRechitClusterZSpread\", \"title\":\"Cluster Z Spread\", \n",
    "                       \"xlabel\":\"Z Spread [cm]\", \"masks\":[],\"bins\":(25, -5, 200), \"logy\": False},\n",
    "            \"cscRechitClusterXYSpread\": {\"filename_base\":\"cscRechitClusterXYSpread\", \"title\":\"Cluster XY Spread\", \n",
    "                       \"xlabel\":\"XY Spread [cm]\", \"masks\":[],\"bins\":(25, -5, 150), \"logy\": False},\n",
    "            \"cscRechitClusterRSpread\": {\"filename_base\":\"cscRechitClusterRSpread\", \"title\":\"Cluster R Spread\", \n",
    "                       \"xlabel\":\"R Spread [cm]\", \"masks\":[],\"bins\":(25, -5, 150), \"logy\": False},\n",
    "            \"cscRechitClusterSkewX\": {\"filename_base\":\"cscRechitClusterSkewX\", \"title\":\"Cluster X Skew\", \n",
    "                       \"xlabel\":\"X Skew [cm]\", \"masks\":[],\"bins\":(25, -150, 150), \"logy\": False},\n",
    "            \"cscRechitClusterSkewY\": {\"filename_base\":\"cscRechitClusterSkewY\", \"title\":\"Cluster Y Skew\", \n",
    "                       \"xlabel\":\"Y Skew [cm]\", \"masks\":[],\"bins\":(25, -150, 150), \"logy\": False},\n",
    "             \"cscRechitClusterSkewZ\": {\"filename_base\":\"cscRechitClusterSkewZ\", \"title\":\"Cluster Z Skew\", \n",
    "                       \"xlabel\":\"Z Skew [cm]\", \"masks\":[],\"bins\":(25, -150, 150), \"logy\": False},\n",
    "            \"cscRechitClusterSkewX\": {\"filename_base\":\"cscRechitClusterSkewX\", \"title\":\"Cluster X Spread\", \n",
    "                       \"xlabel\":\"X Skew [cm]\", \"masks\":[],\"bins\":(25, -150, 150), \"logy\": False},\n",
    "            \"cscRechitClusterFracS1\": {\"filename_base\":\"cscRechitClusterFracS1\", \"title\":\"Fraction of Hits in Station 1\", \n",
    "                       \"xlabel\":\"Station 1 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False},\n",
    "            \"cscRechitClusterFracS2\": {\"filename_base\":\"cscRechitClusterFracS2\", \"title\":\"Fraction of Hits in Station 2\", \n",
    "                       \"xlabel\":\"Station 2 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False},\n",
    "            \"cscRechitClusterFracS3\": {\"filename_base\":\"cscRechitClusterFracS3\", \"title\":\"Fraction of Hits in Station 3\", \n",
    "                       \"xlabel\":\"Station 3 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False},\n",
    "            \"cscRechitClusterFracS4\": {\"filename_base\":\"cscRechitClusterFracS4\", \"title\":\"Fraction of Hits in Station 4\", \n",
    "                       \"xlabel\":\"Station 4 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False},\n",
    "            \"cscRechitClusterFracR1\": {\"filename_base\":\"cscRechitClusterFracR1\", \"title\":\"Fraction of Hits in Ring 1\", \n",
    "                       \"xlabel\":\"Ring 1 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False},\n",
    "            \"cscRechitClusterFracR2\": {\"filename_base\":\"cscRechitClusterFracR2\", \"title\":\"Fraction of Hits in Ring 2\", \n",
    "                       \"xlabel\":\"Ring 2 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False},\n",
    "             \"cscRechitClusterFracR3\": {\"filename_base\":\"cscRechitClusterFracR3\", \"title\":\"Fraction of Hits in Ring 3\", \n",
    "                       \"xlabel\":\"Ring 3 Hits/Total Hits\", \"masks\":[],\"bins\":(25, 0, 1.1), \"logy\": False}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ed064de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on branch cscRechitClusterSize\n",
      "on branch cscRechitClusterDNN_bkgMC_plusBeamHalo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TROOT::Append>: Replacing existing TH1: Data (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: MC (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: Data (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: MC (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: Data (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: MC (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: Data (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: MC (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: Data (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: MC (Potential memory leak).\n"
     ]
    }
   ],
   "source": [
    "individual_plot_info = {}\n",
    "for branch, info_dict in plot_info.items():\n",
    "    if branch!=\"cscRechitClusterSize\" and branch!=\"cscRechitClusterDNN_bkgMC_plusBeamHalo\":continue\n",
    "    filename_base = info_dict[\"filename_base\"]\n",
    "    hist_dict = makeHists(events_data, events_MC, branch, info_dict[\"masks\"], info_dict[\"bins\"])\n",
    "    for plot_hists, plot_hist_dict in hist_dict.items():\n",
    "        individual_plot_info[plot_hists] = {\"MC_hist\": plot_hist_dict[\"MC_hist\"], \"data_hist\": plot_hist_dict[\"data_hist\"], \n",
    "                    \"file_name\": plot_hists, \"title\": info_dict[\"title\"], \"label\": info_dict[\"xlabel\"], \n",
    "                    \"scales\": [plot_hist_dict[\"MC_weights\"], plot_hist_dict[\"data_weights\"]], \"logy\": info_dict[\"logy\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded26041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on branch ZMass\n",
      "on branch puppiMet\n",
      "on branch puppiMetPhi\n",
      "on branch cscRechitClusterMuonDeltaR\n",
      "on branch probe_pT\n",
      "on branch tag_pT\n",
      "on branch probe_phi\n",
      "on branch tag_phi\n",
      "on branch probe_eta\n",
      "on branch tag_eta\n",
      "on branch cscRechitClusterSize\n",
      "on branch cscRechitClusterDNN_bkgMC_plusBeamHalo\n",
      "on branch cscRechitClusterTimeWeighted\n",
      "on branch cscRechitClusterTimeSpreadWeightedAll\n",
      "on branch cscRechitClusterEta\n",
      "on branch cscRechitClusterPhi\n",
      "on branch cscRechitClusterNStation10\n",
      "on branch cscRechitClusterXSpread\n",
      "on branch cscRechitClusterYSpread\n",
      "on branch cscRechitClusterZSpread\n",
      "on branch cscRechitClusterXYSpread\n",
      "on branch cscRechitClusterRSpread\n",
      "on branch cscRechitClusterSkewX\n",
      "on branch cscRechitClusterSkewY\n",
      "on branch cscRechitClusterSkewZ\n"
     ]
    }
   ],
   "source": [
    "individual_plot_info_highMET = {}\n",
    "for branch, info_dict in plot_info.items():\n",
    "    filename_base = info_dict[\"filename_base\"]\n",
    "    hist_dict = makeHists(events_data, events_MC, branch, info_dict[\"masks\"], info_dict[\"bins\"], True)\n",
    "    for plot_hists, plot_hist_dict in hist_dict.items():\n",
    "        individual_plot_info_highMET[plot_hists] = {\"MC_hist\": plot_hist_dict[\"MC_hist\"], \"data_hist\": plot_hist_dict[\"data_hist\"], \n",
    "                    \"file_name\": plot_hists, \"title\": info_dict[\"title\"], \"label\": info_dict[\"xlabel\"], \n",
    "                    \"scales\": [plot_hist_dict[\"MC_weights\"], plot_hist_dict[\"data_weights\"]], \"logy\": info_dict[\"logy\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1497329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cscRechitClusterSize_noCuts\n",
      "cscRechitClusterSize_forwardVeto\n",
      "cscRechitClusterSize_allOtherCuts\n",
      "cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts\n",
      "cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto\n",
      "cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterSize_noCuts/cscRechitClusterSize_noCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterSize_noCuts/cscRechitClusterSize_noCuts_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterSize_forwardVeto/cscRechitClusterSize_forwardVeto_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterSize_forwardVeto/cscRechitClusterSize_forwardVeto_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterSize_allOtherCuts/cscRechitClusterSize_allOtherCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterSize_allOtherCuts/cscRechitClusterSize_allOtherCuts_updatedTNP.png has been created\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts_updatedTNP.png has been created\n"
     ]
    }
   ],
   "source": [
    "plot_output = \"Run2023_preBPix_Data_MC_Comp_finalzedSelections_APSPlots_ForLabel\"\n",
    "os.makedirs(plot_output, exist_ok=True)\n",
    "\n",
    "for plot_type, plot_info_dict in individual_plot_info.items():\n",
    "    print(plot_type)\n",
    "    for boolScale in [True, False]:\n",
    "        c = make_ratio_plot([plot_info_dict[\"MC_hist\"], plot_info_dict[\"data_hist\"]], title = plot_info_dict[\"title\"], label = plot_info_dict[\"label\"], fit = False, in_tags = None, ratio_bounds = [0.1, 4], logy = plot_info_dict[\"logy\"], ratio_index = 0, draw_opt = ['E2','E1'], text = \"\", scale=boolScale, scales = plot_info_dict[\"scales\"])\n",
    "        if boolScale:\n",
    "            scaleString = \"_normalized\"\n",
    "        else:\n",
    "            scaleString=\"\"\n",
    "        os.makedirs(plot_output+\"/\"+plot_info_dict[\"file_name\"], exist_ok=True)\n",
    "        c.SaveAs(plot_output+\"/\"+plot_info_dict[\"file_name\"]+\"/\"+plot_info_dict[\"file_name\"]+scaleString+\"_updatedTNP.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3448c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cscRechitClusterSize_noCuts\n",
      "cscRechitClusterSize_forwardVeto\n",
      "cscRechitClusterSize_allOtherCuts\n",
      "cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts\n",
      "cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto\n",
      "cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterSize_noCuts/cscRechitClusterSize_noCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterSize_noCuts/cscRechitClusterSize_noCuts_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterSize_forwardVeto/cscRechitClusterSize_forwardVeto_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterSize_forwardVeto/cscRechitClusterSize_forwardVeto_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterSize_allOtherCuts/cscRechitClusterSize_allOtherCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioN_{hits}\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterSize_allOtherCuts/cscRechitClusterSize_allOtherCuts_updatedTNP.png has been created\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_noCuts_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto/cscRechitClusterDNN_bkgMC_plusBeamHalo_forwardVeto_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts_normalized_updatedTNP.png has been created\n",
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: c_out_ratioDNN Score\n",
      "Info in <TCanvas::Print>: png file Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts/cscRechitClusterDNN_bkgMC_plusBeamHalo_allOtherCuts_updatedTNP.png has been created\n"
     ]
    }
   ],
   "source": [
    "plot_output = \"Run2023_preBPix_Data_MC_Comp_finalzedSelections_testCode_highMET\"\n",
    "os.makedirs(plot_output, exist_ok=True)\n",
    "\n",
    "for plot_type, plot_info_dict in individual_plot_info.items():\n",
    "    print(plot_type)\n",
    "    for boolScale in [True, False]:\n",
    "        c = make_ratio_plot([plot_info_dict[\"MC_hist\"], plot_info_dict[\"data_hist\"]], title = plot_info_dict[\"title\"], label = plot_info_dict[\"label\"], fit = False, in_tags = None, ratio_bounds = [0.1, 4], logy = plot_info_dict[\"logy\"], ratio_index = 0, draw_opt = ['E2','E1'], text = \"\", scale=boolScale, scales = plot_info_dict[\"scales\"])\n",
    "        if boolScale:\n",
    "            scaleString = \"_normalized\"\n",
    "        else:\n",
    "            scaleString=\"\"\n",
    "        os.makedirs(plot_output+\"/\"+plot_info_dict[\"file_name\"], exist_ok=True)\n",
    "        c.SaveAs(plot_output+\"/\"+plot_info_dict[\"file_name\"]+\"/\"+plot_info_dict[\"file_name\"]+scaleString+\"_updatedTNP.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
